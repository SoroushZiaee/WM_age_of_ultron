{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e3712f-0011-492d-9146-9cd39443e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462feb5c-1fb1-48b7-ad96-e9b4ddadb000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: h5py in /localscratch/soroush1.36064232.0/env/lib/python3.11/site-packages (3.12.0+computecanada)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /localscratch/soroush1.36064232.0/env/lib/python3.11/site-packages (from h5py) (1.26.4+computecanada)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6dece1-cbb3-4a28-a145-da9dab2c2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "\n",
    "import logging\n",
    "from abc import abstractmethod\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6881d044-9382-4610-a57e-c4db699c597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehavioralMetrics:\n",
    "    def __init__(\n",
    "        self,\n",
    "        h5_path: str = None,\n",
    "        dataset_name: str = None,\n",
    "        verbose: bool = False,\n",
    "        df: pd.DataFrame = None,\n",
    "    ) -> None:\n",
    "        if df is not None:\n",
    "            self.behavioral_data = df\n",
    "            self.verbose = verbose\n",
    "            return\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.h5_path = h5_path\n",
    "        self.verbose = verbose\n",
    "        self.read_h5()  # read the h5 file\n",
    "        self.h5_processing()  # process the h5 file\n",
    "\n",
    "    def h5_processing(self):\n",
    "        df = pd.DataFrame(\n",
    "            self.h5_obj[self.dataset_name][:]\n",
    "        ).T  # convert the h5 dataset to a pandas dataframe\n",
    "        df.columns = [\n",
    "            \"image_number\",\n",
    "            \"fix_dur_sample\",\n",
    "            \"presentation_time_ms\",\n",
    "            \"trial_completed\",\n",
    "            \"target\",\n",
    "            \"distractor\",\n",
    "            \"correct\",\n",
    "            \"reaction_time_ms\",\n",
    "            \"delay_ms\",\n",
    "            \"date\",\n",
    "        ]  # rename the columns\n",
    "        df.columns = df.columns.astype(str)\n",
    "\n",
    "        # df = df[df[\"trial_completed\"] == 1]\n",
    "        # for column_name in df.columns:\n",
    "        #     df[column_name] = df[column_name].astype(int) # convert the columns to int\n",
    "\n",
    "        self.behavioral_data = df\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"h5 file processed successfully!\")\n",
    "\n",
    "    def read_h5(self):\n",
    "        h5_obj = h5py.File(self.h5_path, \"r\")\n",
    "        self.h5_obj = h5_obj\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"h5 file read successfully!\")\n",
    "\n",
    "class BehavioralMetrics:\n",
    "    def __init__(\n",
    "        self,\n",
    "        h5_path: str = None,\n",
    "        dataset_name: str = None,\n",
    "        verbose: bool = False,\n",
    "        df: pd.DataFrame = None,\n",
    "    ) -> None:\n",
    "        if df is not None:\n",
    "            self.behavioral_data = df\n",
    "            self.verbose = verbose\n",
    "            return\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.h5_path = h5_path\n",
    "        self.verbose = verbose\n",
    "        self.read_h5()  # read the h5 file\n",
    "        self.h5_processing()  # process the h5 file\n",
    "\n",
    "    def h5_processing(self):\n",
    "        df = pd.DataFrame(\n",
    "            self.h5_obj[self.dataset_name][:]\n",
    "        ).T  # convert the h5 dataset to a pandas dataframe\n",
    "        df.columns = [\n",
    "            \"image_number\",\n",
    "            \"fix_dur_sample\",\n",
    "            \"presentation_time_ms\",\n",
    "            \"trial_completed\",\n",
    "            \"target\",\n",
    "            \"distractor\",\n",
    "            \"correct\",\n",
    "            \"reaction_time_ms\",\n",
    "            \"delay_ms\",\n",
    "            \"date\",\n",
    "        ]  # rename the columns\n",
    "        df.columns = df.columns.astype(str)\n",
    "\n",
    "        # df = df[df[\"trial_completed\"] == 1]\n",
    "        # for column_name in df.columns:\n",
    "        #     df[column_name] = df[column_name].astype(int) # convert the columns to int\n",
    "\n",
    "        self.behavioral_data = df\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"h5 file processed successfully!\")\n",
    "\n",
    "    def read_h5(self):\n",
    "        h5_obj = h5py.File(self.h5_path, \"r\")\n",
    "        self.h5_obj = h5_obj\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"h5 file read successfully!\")\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        df = self.behavioral_data.copy()\n",
    "        df = df[[\"image_number\", \"target\", \"distractor\", \"correct\"]]\n",
    "        df.dropna(subset=[\"correct\"], inplace=True)\n",
    "        df.sort_values(by=[\"target\", \"image_number\", \"distractor\"], inplace=True)\n",
    "\n",
    "        accuracies = df.groupby(\"image_number\")[\"correct\"].mean().unstack().to_numpy()\n",
    "\n",
    "        return (\n",
    "            self.behavioral_data[\"correct\"].dropna().mean()\n",
    "        )  # calculate the accuracy of the behavioral data\n",
    "\n",
    "    def get_standard_error(self, iteration: int = 100):\n",
    "        behavior_value = self.behavioral_data[\"correct\"].dropna().to_numpy()\n",
    "\n",
    "        # To ensure the error bars do not go beyond 0 or 1,\n",
    "        # you can use the adjusted Wald method (also known as the Agresti-Coull interval)\n",
    "        # to calculate the SE for a proportion.\n",
    "        # This method adjusts the proportion and the sample size slightly to account for the fact that the sampling distribution of a proportion is not symmetric,\n",
    "        # especially with small sample sizes or proportions near 0 or 1.\n",
    "\n",
    "        p_adj = (behavior_value.sum() + 2) / (len(behavior_value) + 4)\n",
    "        se = np.sqrt(p_adj * (1 - p_adj) / len(behavior_value))\n",
    "\n",
    "        print(f\"{len(behavior_value) = }\")\n",
    "        se = np.std(behavior_value)\n",
    "        return se  # calculate the standard deviation of the behavioral data\n",
    "\n",
    "    def get_info(self):\n",
    "        df = self.behavioral_data.copy()\n",
    "        df = df[[\"image_number\", \"target\", \"distractor\", \"correct\"]]\n",
    "        df.sort_values(by=[\"target\", \"image_number\", \"distractor\"], inplace=True)\n",
    "        df.dropna(subset=[\"correct\"], inplace=True)\n",
    "\n",
    "        # Print the unique number of images\n",
    "        print(f\"unique Images: {df['image_number'].nunique()}\")\n",
    "\n",
    "        # print the unique number of targets\n",
    "        print(f\"unique Targets: {df['target'].nunique()}\")\n",
    "\n",
    "        # print the unique number of distractors per target\n",
    "        plt.figure(figsize=(3, 2))\n",
    "        df.groupby(\"target\")[\"distractor\"].nunique().plot(kind=\"bar\")\n",
    "        plt.title(\"unique Distractors per target\")\n",
    "        plt.grid()\n",
    "        plt.yticks(range(1, 10))\n",
    "        plt.show()\n",
    "        # print(f\"unique Distractors: {df.groupby('target')['distractor'].nunique()}\")\n",
    "\n",
    "        # plot bar plot the unique image number per target\n",
    "        plt.figure(figsize=(3, 2))\n",
    "        df.groupby(\"target\")[\"image_number\"].nunique().plot(kind=\"bar\")\n",
    "        plt.title(\"unique Image number per target\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        # print(f\"unique Image number per target: {df.groupby('target')['image_number'].nunique()}\")\n",
    "\n",
    "        # show how many trials are there for each target\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        ax = df.groupby(\"target\")[\"correct\"].count().plot(kind=\"bar\")\n",
    "        plt.title(\"Trials per target\")\n",
    "        plt.grid()\n",
    "\n",
    "        # Add text annotations to the bars\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(\n",
    "                str(p.get_height()),\n",
    "                (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # show how many trials are there for each image\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        # plot the histogram of the trials per image\n",
    "        df.groupby(\"image_number\")[\"correct\"].count().plot(\n",
    "            kind=\"hist\", bins=10, rwidth=0.8, color=\"#0504aa\"\n",
    "        )\n",
    "        plt.title(\"Histogram Trials per image\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "    @abstractmethod\n",
    "    def calculate_behavioral_metric(self):\n",
    "        raise NotImplementedError(\"Subclass must implement this method!\")\n",
    "\n",
    "\n",
    "class BehavioralMetricsI(BehavioralMetrics):\n",
    "    def __init__(\n",
    "        self,\n",
    "        h5_path: str = None,\n",
    "        dataset_name: str = None,\n",
    "        verbose: bool = False,\n",
    "        df: pd.DataFrame = None,\n",
    "    ) -> None:\n",
    "        super().__init__(h5_path, dataset_name, verbose, df)\n",
    "        self.behavioral_metric = {\"I1\": None, \"I2\": None}\n",
    "        self.calculate_behavioral_metric()  # calculate the behavioral metric\n",
    "\n",
    "    def calculate_behavioral_metric(self):\n",
    "        # sort base on target class\n",
    "        df_delay_100_slice = self.behavioral_data[\n",
    "            [\"image_number\", \"target\", \"distractor\", \"correct\"]\n",
    "        ]  # slice the dataframe\n",
    "\n",
    "        df_delay_100_slice.sort_values(\n",
    "            by=[\"target\", \"image_number\", \"distractor\"], inplace=True\n",
    "        )  # sort the dataframe base on target class and image number and distractor class and inplace the matrix\n",
    "        df_delay_100_slice.dropna(\n",
    "            subset=[\"correct\"], inplace=True\n",
    "        )  # drop the nan values in the correct column and inplace the matrix\n",
    "\n",
    "        # calculate the I1 behavioral metric: the mean of correct responses for each image regardless of distractor class\n",
    "        b_i1 = self.calculate_bi1(\n",
    "            df_delay_100_slice\n",
    "        )  # calculate the I1 behavior metric\n",
    "\n",
    "        b_i2 = self.calculate_bi2(\n",
    "            df_delay_100_slice\n",
    "        )  # calculate the I1 behavior metric\n",
    "        self.behavioral_metric = {\"B.I1\": b_i1, \"B.I2\": b_i2}\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"I1 behavioral metric calculated successfully!\")\n",
    "\n",
    "    def calculate_bi2(self, df):\n",
    "        # Group by both 'image_number' and 'distractor', and calculate the mean of 'correct'\n",
    "        grouped = df.groupby([\"image_number\", \"distractor\"])[\"correct\"].mean()\n",
    "\n",
    "        # Reshape the data into a list of matrices, one for each unique 'image_number'\n",
    "        images = [\n",
    "            group.unstack().to_numpy().ravel() for _, group in grouped.groupby(level=0)\n",
    "        ]\n",
    "\n",
    "        return np.array(images)\n",
    "\n",
    "    def get_bi1(self):\n",
    "        return self.behavioral_metric[\"B.I1\"]\n",
    "\n",
    "    def calculate_bi1(self, df):\n",
    "        return (\n",
    "            df.groupby([\"image_number\"])\n",
    "            .agg({\"correct\": \"mean\"})\n",
    "            .unstack()\n",
    "            .to_numpy()\n",
    "            .reshape(-1, 1)\n",
    "        )\n",
    "\n",
    "    def calculate_internal_reliability(self):\n",
    "        intenal_consistency = []\n",
    "        for _ in range(100):\n",
    "            df = self.behavioral_data.copy()\n",
    "            df = df[[\"image_number\", \"target\", \"distractor\", \"correct\"]]\n",
    "            # Assuming df is your pandas DataFrame\n",
    "            df = df.sample(frac=1).reset_index(\n",
    "                drop=True\n",
    "            )  # randomize the behavioral data\n",
    "            df = df.dropna(\n",
    "                subset=[\"correct\"]\n",
    "            )  # drop the nan values in the correct column\n",
    "            df.sort_values(by=[\"target\", \"image_number\", \"distractor\"], inplace=True)\n",
    "\n",
    "            split1, split2 = [], []\n",
    "            for image_number in df[\"image_number\"].unique():\n",
    "                image_trials = df[df[\"image_number\"] == image_number]\n",
    "\n",
    "                # split the trials into two halves with equal number of trials\n",
    "                # print(f\"{len(image_trials) = }\")\n",
    "                # print(f\"{len(image_trials) = }\")\n",
    "                # print(f\"{image_trials.iloc[: len(image_trials) // 2].shape = }\")\n",
    "                # print(f\"{image_trials.iloc[len(image_trials) // 2, :].shape = }\")\n",
    "\n",
    "                if diff := len(image_trials) % 2:\n",
    "                    image_trials = image_trials[:-diff]\n",
    "\n",
    "                # print(f\"{image_trials.iloc[: len(image_trials) // 2].shape = }\")\n",
    "                # print(f\"{image_trials.iloc[len(image_trials) // 2, :].shape = }\")\n",
    "\n",
    "                split1.append(\n",
    "                    image_trials.iloc[: len(image_trials) // 2][\"correct\"].mean()\n",
    "                )\n",
    "                split2.append(\n",
    "                    image_trials.iloc[len(image_trials) // 2 :][\"correct\"].mean()\n",
    "                )\n",
    "\n",
    "            # print(f\"{len(split1) = }\")\n",
    "            # print(f\"{len(split2) = }\")\n",
    "\n",
    "            correlation, _ = pearsonr(split1, split2)\n",
    "\n",
    "            split_half_reliability = 2 * correlation / (1 + correlation)\n",
    "            intenal_consistency.append(split_half_reliability)\n",
    "            # print(f\"Split-half reliability coefficient: {split_half_reliability}\")\n",
    "\n",
    "        print(f\"{np.mean(intenal_consistency) = }\")\n",
    "\n",
    "    def dataframe_split_half(self):\n",
    "        # randomize the behavioral data\n",
    "        df = self.behavioral_data.copy()\n",
    "        # Assuming df is your pandas DataFrame\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        df = df[[\"image_number\", \"target\", \"distractor\", \"correct\"]]\n",
    "        df = df.dropna(subset=[\"correct\"])\n",
    "\n",
    "        # Calculate the number of trials for unique trials\n",
    "        images_repetition = df.groupby(\"image_number\").size()\n",
    "        min_repetition = images_repetition.min()\n",
    "\n",
    "        # if the minium repetition is odd, subtract 1\n",
    "        if min_repetition % 2 != 0:\n",
    "            min_repetition -= 1\n",
    "\n",
    "        # Create a new DataFrame to store the equalized data\n",
    "        equalized_df = []\n",
    "\n",
    "        for image_number in df[\"image_number\"].unique():\n",
    "            image_trials = df[df[\"image_number\"] == image_number]\n",
    "\n",
    "            # If the number of trials is more than the minimum, sample 'min_trials' number of rows\n",
    "            if len(image_trials) > min_repetition:\n",
    "                image_trials = image_trials.sample(n=min_repetition)\n",
    "\n",
    "            # Append the sampled rows to the new DataFrame\n",
    "            equalized_df.append(image_trials)\n",
    "\n",
    "        # Reset the index of the new DataFrame\n",
    "        # Concatenate all sampled DataFrames into one\n",
    "        equalized_df = pd.concat(equalized_df).reset_index(drop=True)\n",
    "\n",
    "        # Define a function that splits each group into two DataFrames\n",
    "        def split_group(group):\n",
    "            half = len(group) // 2\n",
    "            return group.iloc[:half], group.iloc[half:]\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            halves = equalized_df.groupby(\"image_number\").apply(\n",
    "                lambda x: split_group(x)\n",
    "            )\n",
    "        # Concatenate the first and second halves separately to form two DataFrames\n",
    "\n",
    "        df1 = pd.concat([half[0] for half in halves])\n",
    "        df2 = pd.concat([half[1] for half in halves])\n",
    "\n",
    "        # Reset index for both DataFrames\n",
    "        df1 = df1.reset_index(drop=True)\n",
    "        df2 = df2.reset_index(drop=True)\n",
    "\n",
    "        return df1, df2\n",
    "\n",
    "    def plot_behavioral_metric_b1(self):\n",
    "        # Plot the data as a heatmap\n",
    "        fig, ax = plt.subplots(figsize=(0.5, 6))\n",
    "        cax = ax.imshow(self.get_bi1(), aspect=\"auto\", cmap=\"Spectral\")\n",
    "\n",
    "        # Add a colorbar\n",
    "        fig.colorbar(cax)\n",
    "\n",
    "        # Remove x-axis since it's not meaningful in this context\n",
    "        ax.set_xticks([])\n",
    "\n",
    "        # Optionally, you can set the y-axis to show indices or other meaningful labels\n",
    "        ax.set_yticks(\n",
    "            []\n",
    "        )  # or set to a range of values that are meaningful for your data\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"I1 behavioral metric plotted successfully!\")\n",
    "\n",
    "        return cax\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Image-based Behavioral Metric\"\n",
    "\n",
    "\n",
    "class BehavioralMetricsO(BehavioralMetrics):\n",
    "    def __init__(self, h5_path: str, dataset_name: str, verbose: bool = False) -> None:\n",
    "        super().__init__(h5_path, dataset_name, verbose)\n",
    "        self.behavioral_metric = {\"B.O1\": None, \"B.O2\": None}\n",
    "        self.calculate_behavioral_metric()  # calculate the behavioral metric\n",
    "\n",
    "    def calculate_behavioral_metric(self):\n",
    "        df_delay_100_slice = self.behavioral_data[\n",
    "            [\"image_number\", \"target\", \"distractor\", \"correct\"]\n",
    "        ]\n",
    "\n",
    "        # Create target_unique_values dictionary more efficiently\n",
    "        unique_targets = df_delay_100_slice[\"target\"].dropna().unique().astype(int)\n",
    "        target_unique_values = {\n",
    "            target: [] for target in sorted(unique_targets)\n",
    "        }  # Sorted the tagets to make the dictionary more readable\n",
    "\n",
    "        # Calculate images_per_class more efficiently using groupby\n",
    "        grouped = df_delay_100_slice.groupby([\"target\", \"distractor\"]).size()\n",
    "        images_per_class = grouped.values\n",
    "\n",
    "        # Populate target_unique_values dictionary\n",
    "        max_length = max(images_per_class)\n",
    "\n",
    "        for target in target_unique_values.keys():\n",
    "            temp_df = df_delay_100_slice[df_delay_100_slice[\"target\"] == target]\n",
    "            for distractor in target_unique_values.keys():\n",
    "                if target == distractor:\n",
    "                    target_unique_values[target].append(np.full(max_length, np.nan))\n",
    "                else:\n",
    "                    corr_array = temp_df[temp_df[\"distractor\"] == distractor][\n",
    "                        \"correct\"\n",
    "                    ].to_numpy()\n",
    "\n",
    "                    # Pad the array if it's shorter than max_length\n",
    "                    pad_length = max_length - len(corr_array)\n",
    "                    if pad_length > 0:\n",
    "                        corr_array = np.pad(\n",
    "                            corr_array,\n",
    "                            (0, pad_length),\n",
    "                            \"constant\",\n",
    "                            constant_values=np.nan,\n",
    "                        )\n",
    "                    target_unique_values[target].append(corr_array)\n",
    "\n",
    "        # Convert target_unique_values dictionary to List\n",
    "        target_unique_values_array = np.array(\n",
    "            [\n",
    "                np.array(target_unique_values[target])\n",
    "                for target in sorted(target_unique_values.keys())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # RuntimeWarning: Mean of empty slice\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            b_o2 = np.nanmean(target_unique_values_array, axis=2)\n",
    "\n",
    "        b_o1 = np.nanmean(target_unique_values_array, axis=(2, 1)).reshape(-1, 1)\n",
    "        # calculate the O1 behavior metric\n",
    "        self.behavioral_metric = {\"B.O1\": b_o1, \"B.O2\": b_o2}\n",
    "\n",
    "    def get_bo1(self):\n",
    "        return self.behavioral_metric[\"B.O1\"]\n",
    "\n",
    "    def get_bo2(self):\n",
    "        return self.behavioral_metric[\"B.O2\"]\n",
    "\n",
    "    def plot_behavioral_metric_b1(self):\n",
    "        # Plot the data as a heatmap\n",
    "        fig, ax = plt.subplots(figsize=(0.5, 6))\n",
    "        cax = ax.imshow(self.get_bo1(), aspect=\"auto\", cmap=\"Spectral\")\n",
    "\n",
    "        # Add a colorbar\n",
    "        fig.colorbar(cax)\n",
    "\n",
    "        # Remove x-axis since it's not meaningful in this context\n",
    "        ax.set_xticks([])\n",
    "\n",
    "        # Optionally, you can set the y-axis to show indices or other meaningful labels\n",
    "        ax.set_yticks(\n",
    "            []\n",
    "        )  # or set to a range of values that are meaningful for your data\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"I1 behavioral metric plotted successfully!\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def plot_behavioral_metric_b2(self):\n",
    "        # Plot the data as a heatmap\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        cax = ax.imshow(self.get_bo2(), aspect=\"auto\", cmap=\"Spectral\")\n",
    "\n",
    "        # Add a colorbar\n",
    "        fig.colorbar(cax)\n",
    "\n",
    "        # Remove x-axis since it's not meaningful in this context\n",
    "        ax.set_xticks([])\n",
    "\n",
    "        # Optionally, you can set the y-axis to show indices or other meaningful labels\n",
    "        ax.set_yticks(\n",
    "            []\n",
    "        )  # or set to a range of values that are meaningful for your data\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"I1 behavioral metric plotted successfully!\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Object-based Behavioral Metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4e7248-30ff-416f-8387-1dc9da4b06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_obj =  BehavioralMetricsI(h5_path=\"data/wm_delay_data_v2.h5\", dataset_name=\"delay_100\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e2642ae-ec2b-48ca-8cb5-e072d80088b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9125    ],\n",
       "       [0.95604396],\n",
       "       [0.96470588],\n",
       "       [0.8988764 ],\n",
       "       [0.9494382 ],\n",
       "       [0.9202454 ],\n",
       "       [0.9       ],\n",
       "       [0.8373494 ],\n",
       "       [0.86781609],\n",
       "       [0.93529412],\n",
       "       [0.96341463],\n",
       "       [0.87272727],\n",
       "       [0.87719298],\n",
       "       [0.92352941],\n",
       "       [0.92771084],\n",
       "       [0.87878788],\n",
       "       [0.90588235],\n",
       "       [0.89285714],\n",
       "       [0.89820359],\n",
       "       [0.84848485],\n",
       "       [0.91812865],\n",
       "       [0.82738095],\n",
       "       [0.75739645],\n",
       "       [0.86982249],\n",
       "       [0.88554217],\n",
       "       [0.9127907 ],\n",
       "       [0.82022472],\n",
       "       [0.95092025],\n",
       "       [0.90643275],\n",
       "       [0.93292683],\n",
       "       [0.85714286],\n",
       "       [0.83908046],\n",
       "       [0.81547619],\n",
       "       [0.86857143],\n",
       "       [0.75882353],\n",
       "       [0.9408284 ],\n",
       "       [0.91566265],\n",
       "       [0.84756098],\n",
       "       [0.87261146],\n",
       "       [0.91071429],\n",
       "       [0.99438202],\n",
       "       [0.9245283 ],\n",
       "       [1.        ],\n",
       "       [0.95375723],\n",
       "       [0.98214286],\n",
       "       [0.95238095],\n",
       "       [0.98224852],\n",
       "       [0.97058824],\n",
       "       [0.92352941],\n",
       "       [0.98830409],\n",
       "       [0.96470588],\n",
       "       [0.92771084],\n",
       "       [0.95705521],\n",
       "       [0.97222222],\n",
       "       [0.97530864],\n",
       "       [0.85380117],\n",
       "       [0.97727273],\n",
       "       [0.97701149],\n",
       "       [0.95027624],\n",
       "       [0.97647059],\n",
       "       [0.92307692],\n",
       "       [0.86746988],\n",
       "       [0.93529412],\n",
       "       [0.88439306],\n",
       "       [0.92941176],\n",
       "       [0.94610778],\n",
       "       [0.92941176],\n",
       "       [0.9122807 ],\n",
       "       [0.95302013],\n",
       "       [0.8253012 ],\n",
       "       [0.95597484],\n",
       "       [0.91515152],\n",
       "       [0.97142857],\n",
       "       [0.92941176],\n",
       "       [0.97206704],\n",
       "       [0.92121212],\n",
       "       [0.92134831],\n",
       "       [0.95209581],\n",
       "       [0.91616766],\n",
       "       [0.93373494],\n",
       "       [0.93567251],\n",
       "       [0.81065089],\n",
       "       [0.98295455],\n",
       "       [0.98830409],\n",
       "       [0.92352941],\n",
       "       [0.94413408],\n",
       "       [0.95294118],\n",
       "       [0.87248322],\n",
       "       [0.87349398],\n",
       "       [0.96685083],\n",
       "       [0.89090909],\n",
       "       [0.86982249],\n",
       "       [0.97777778],\n",
       "       [0.95833333],\n",
       "       [0.89090909],\n",
       "       [0.94047619],\n",
       "       [0.72611465],\n",
       "       [0.9       ],\n",
       "       [0.94152047],\n",
       "       [0.93641618],\n",
       "       [0.98773006],\n",
       "       [0.95679012],\n",
       "       [0.9702381 ],\n",
       "       [0.97058824],\n",
       "       [0.97633136],\n",
       "       [0.92727273],\n",
       "       [0.97311828],\n",
       "       [0.98333333],\n",
       "       [0.96      ],\n",
       "       [0.94152047],\n",
       "       [0.96067416],\n",
       "       [0.91907514],\n",
       "       [0.97546012],\n",
       "       [0.97660819],\n",
       "       [0.77647059],\n",
       "       [0.79411765],\n",
       "       [0.9689441 ],\n",
       "       [0.94610778],\n",
       "       [0.98809524],\n",
       "       [0.97109827],\n",
       "       [0.90384615],\n",
       "       [0.95882353],\n",
       "       [0.95151515],\n",
       "       [0.90566038],\n",
       "       [0.91034483],\n",
       "       [0.89873418],\n",
       "       [0.95783133],\n",
       "       [0.95266272],\n",
       "       [0.88826816],\n",
       "       [0.87804878],\n",
       "       [0.9132948 ],\n",
       "       [0.89221557],\n",
       "       [0.8956044 ],\n",
       "       [0.83333333],\n",
       "       [0.95857988],\n",
       "       [0.9125    ],\n",
       "       [0.88957055],\n",
       "       [0.95321637],\n",
       "       [0.86666667],\n",
       "       [0.85542169],\n",
       "       [0.98192771],\n",
       "       [0.95808383],\n",
       "       [0.95833333],\n",
       "       [0.90123457],\n",
       "       [0.93037975],\n",
       "       [0.93567251],\n",
       "       [0.9244186 ],\n",
       "       [0.86982249],\n",
       "       [0.98285714],\n",
       "       [0.96511628],\n",
       "       [0.90909091],\n",
       "       [0.98181818],\n",
       "       [0.97368421],\n",
       "       [0.89032258],\n",
       "       [0.95321637],\n",
       "       [0.97575758],\n",
       "       [0.9695122 ],\n",
       "       [0.96470588],\n",
       "       [0.8969697 ],\n",
       "       [0.97560976],\n",
       "       [0.63841808],\n",
       "       [0.96319018],\n",
       "       [0.92941176],\n",
       "       [0.98795181],\n",
       "       [0.82634731],\n",
       "       [0.96296296],\n",
       "       [0.9760479 ],\n",
       "       [0.98823529],\n",
       "       [0.95488722],\n",
       "       [0.62345679],\n",
       "       [0.97633136],\n",
       "       [0.8253012 ],\n",
       "       [0.58333333],\n",
       "       [0.98      ],\n",
       "       [0.92810458],\n",
       "       [0.98823529],\n",
       "       [0.97590361],\n",
       "       [0.98757764],\n",
       "       [0.98843931],\n",
       "       [0.73652695],\n",
       "       [0.95857988],\n",
       "       [0.94666667],\n",
       "       [0.66666667],\n",
       "       [0.97005988],\n",
       "       [0.90285714],\n",
       "       [0.8969697 ],\n",
       "       [0.94011976],\n",
       "       [0.97619048],\n",
       "       [0.91612903],\n",
       "       [0.98214286],\n",
       "       [0.98159509],\n",
       "       [0.98159509],\n",
       "       [0.78881988],\n",
       "       [0.98734177],\n",
       "       [0.96969697],\n",
       "       [0.9125    ],\n",
       "       [0.9122807 ],\n",
       "       [0.76582278],\n",
       "       [0.91724138],\n",
       "       [0.90384615]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj.behavioral_metric[\"B.I1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eaf0a5-2ffb-4c24-9d0e-4cb369a23e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62b306a-5c8e-4d8a-b446-d865d3a782e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_number</th>\n",
       "      <th>fix_dur_sample</th>\n",
       "      <th>presentation_time_ms</th>\n",
       "      <th>trial_completed</th>\n",
       "      <th>target</th>\n",
       "      <th>distractor</th>\n",
       "      <th>correct</th>\n",
       "      <th>reaction_time_ms</th>\n",
       "      <th>delay_ms</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>581.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20160417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20160418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>688.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20160419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1519.263</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20160421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>554.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20160423.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_number  fix_dur_sample  presentation_time_ms  trial_completed  \\\n",
       "0           0.0             1.0                 100.0              1.0   \n",
       "1           0.0             0.0                 100.0              1.0   \n",
       "2           0.0             1.0                 100.0              1.0   \n",
       "3           0.0             1.0                 100.0              1.0   \n",
       "4           0.0             1.0                 100.0              1.0   \n",
       "\n",
       "   target  distractor  correct  reaction_time_ms  delay_ms        date  \n",
       "0     0.0         6.0      1.0           581.000     100.0  20160417.0  \n",
       "1     NaN         NaN      NaN               NaN     100.0  20160418.0  \n",
       "2     0.0         9.0      1.0           688.000     100.0  20160419.0  \n",
       "3     0.0         1.0      0.0          1519.263     100.0  20160421.0  \n",
       "4     0.0         3.0      1.0           554.000     100.0  20160423.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj.behavioral_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9572aa2-e398-4d4b-892f-91c19843f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36641 entries, 0 to 36640\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   image_number          36641 non-null  float64\n",
      " 1   fix_dur_sample        36641 non-null  float64\n",
      " 2   presentation_time_ms  36641 non-null  float64\n",
      " 3   trial_completed       36641 non-null  float64\n",
      " 4   target                33471 non-null  float64\n",
      " 5   distractor            33471 non-null  float64\n",
      " 6   correct               33471 non-null  float64\n",
      " 7   reaction_time_ms      33471 non-null  float64\n",
      " 8   delay_ms              36641 non-null  float64\n",
      " 9   date                  36641 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "bm_obj.behavioral_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f0d3e7-c24f-4f23-9fce-0a2901baccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "        99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "       110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "       121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "       132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142.,\n",
       "       143., 144., 145., 146., 147., 148., 149., 150., 151., 152., 153.,\n",
       "       154., 155., 156., 157., 158., 159., 160., 161., 162., 163., 164.,\n",
       "       165., 166., 167., 168., 169., 170., 171., 172., 173., 174., 175.,\n",
       "       176., 177., 178., 179., 180., 181., 182., 183., 184., 185., 186.,\n",
       "       187., 188., 189., 190., 191., 192., 193., 194., 195., 196., 197.,\n",
       "       198., 199.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj.behavioral_data[\"image_number\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "954a21a1-dd3f-4f7f-8c88-44dd60ee025b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_number\n",
       "57.0     312\n",
       "168.0    291\n",
       "193.0    216\n",
       "173.0    214\n",
       "192.0    211\n",
       "        ... \n",
       "172.0    170\n",
       "141.0    170\n",
       "155.0    169\n",
       "90.0     168\n",
       "136.0    167\n",
       "Name: count, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj.behavioral_data.sort_values(by=[\"image_number\"]).image_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ab6aa43-22fb-4425-9a2c-8b32b131d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = bm_obj.behavioral_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61880b44-475c-4b8f-8aca-1bdf35e53dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp[temp[\"image_number\"] == 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
