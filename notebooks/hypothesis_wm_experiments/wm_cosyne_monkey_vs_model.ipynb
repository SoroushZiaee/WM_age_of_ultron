{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cb74b9-e93b-49fa-82d7-8b94888611ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created results directory: correlation_monkey_and_model_temp\n",
      "\n",
      "Processing delay: 100ms\n",
      "model_data.mean() = 0.6497701163731606, monkey_data.mean() = 0.918082398023673\n",
      "Saved plot: correlation_monkey_and_model_temp/correlation_plot_100ms.png\n",
      "Saved data: correlation_monkey_and_model_temp/correlation_data_100ms.npz\n",
      "\n",
      "Processing delay: 400ms\n",
      "model_data.mean() = 0.6341095927948143, monkey_data.mean() = 0.922275953163999\n",
      "Saved plot: correlation_monkey_and_model_temp/correlation_plot_400ms.png\n",
      "Saved data: correlation_monkey_and_model_temp/correlation_data_400ms.npz\n",
      "\n",
      "Processing delay: 800ms\n",
      "model_data.mean() = 0.5716948009513231, monkey_data.mean() = 0.8921462201243031\n",
      "Saved plot: correlation_monkey_and_model_temp/correlation_plot_800ms.png\n",
      "Saved data: correlation_monkey_and_model_temp/correlation_data_800ms.npz\n",
      "\n",
      "Processing delay: 1200ms\n",
      "model_data.mean() = 0.5516149908845951, monkey_data.mean() = 0.8416626776251266\n",
      "Saved plot: correlation_monkey_and_model_temp/correlation_plot_1200ms.png\n",
      "Saved data: correlation_monkey_and_model_temp/correlation_data_1200ms.npz\n",
      "Saved summary plot: correlation_monkey_and_model_temp/correlation_summary.png\n",
      "\n",
      "Saved summary results: correlation_monkey_and_model_temp/correlation_results.json\n",
      "\n",
      "Summary of correlations:\n",
      "----------------------\n",
      "Delay 100ms:\n",
      "  Correlation: 0.281\n",
      "  P-value: 5.540e-05\n",
      "Delay 400ms:\n",
      "  Correlation: 0.163\n",
      "  P-value: 2.071e-02\n",
      "Delay 800ms:\n",
      "  Correlation: -0.020\n",
      "  P-value: 7.758e-01\n",
      "Delay 1200ms:\n",
      "  Correlation: -0.158\n",
      "  P-value: 2.542e-02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def create_results_directory():\n",
    "    \"\"\"\n",
    "    Create a directory for storing correlation results.\n",
    "    Returns the path to the created directory.\n",
    "    \"\"\"\n",
    "    base_dir = \"correlation_monkey_and_model_temp\"\n",
    "    # Add timestamp to avoid overwriting\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # results_dir = f\"{base_dir}_{timestamp}\"\n",
    "    results_dir = f\"{base_dir}\"\n",
    "    \n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"Created results directory: {results_dir}\")\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "def load_and_correlate_behavior(model_path, model_template, monkey_path, monkey_template, delay):\n",
    "    \"\"\"\n",
    "    Load and correlate model and monkey behavioral data for a specific delay.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_path : str\n",
    "        Path to model behavior data\n",
    "    model_template : str\n",
    "        Template string for model behavior filenames\n",
    "    monkey_path : str\n",
    "        Path to monkey behavior data\n",
    "    monkey_template : str\n",
    "        Template string for monkey behavior filenames\n",
    "    delay : int\n",
    "        Delay time in milliseconds\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (model_data, monkey_data, correlation_coefficient, p_value)\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    model_file = model_path + model_template.format(delay)\n",
    "    monkey_file = monkey_path + monkey_template.format(delay)\n",
    "    \n",
    "    model_data = np.load(model_file)\n",
    "    monkey_data = np.load(monkey_file)\n",
    "\n",
    "    print(f\"{model_data.mean() = }, {monkey_data.mean() = }\")\n",
    "    \n",
    "    # Flatten arrays if they're multidimensional\n",
    "    model_data = model_data.flatten()\n",
    "    monkey_data = monkey_data.flatten()\n",
    "    \n",
    "    # Calculate correlation\n",
    "    r, p = stats.pearsonr(model_data, monkey_data)\n",
    "    \n",
    "    return model_data, monkey_data, r, p\n",
    "\n",
    "def plot_correlation(model_data, monkey_data, delay, r, p):\n",
    "    \"\"\"\n",
    "    Create a scatter plot of model vs monkey behavioral data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_data : array-like\n",
    "        Model behavioral data\n",
    "    monkey_data : array-like\n",
    "        Monkey behavioral data\n",
    "    delay : int\n",
    "        Delay time in milliseconds\n",
    "    r : float\n",
    "        Correlation coefficient\n",
    "    p : float\n",
    "        P-value of correlation\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Create scatter plot\n",
    "    sns.scatterplot(x=monkey_data, y=model_data, alpha=0.5)\n",
    "    \n",
    "    # Add correlation line\n",
    "    z = np.polyfit(monkey_data, model_data, 1)\n",
    "    p_fit = np.poly1d(z)\n",
    "    plt.plot(monkey_data, p_fit(monkey_data), \"r--\", alpha=0.8, label='Correlation Line')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Monkey Behavior')\n",
    "    plt.ylabel('Model Behavior')\n",
    "    plt.title(f'Model vs Monkey Behavior Correlation\\nDelay: {delay}ms, r={r:.3f}, p={p:.3e}')\n",
    "    \n",
    "    # Add unity line\n",
    "    min_val = min(plt.xlim()[0], plt.ylim()[0])\n",
    "    max_val = max(plt.xlim()[1], plt.ylim()[1])\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.3, label='Unity Line')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_correlation_summary(results, results_dir):\n",
    "    \"\"\"\n",
    "    Create a bar plot comparing correlations across all delays.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Dictionary containing correlation results for each delay\n",
    "    results_dir : str\n",
    "        Directory to save the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Extract delays and correlations\n",
    "    delays = [int(delay) for delay in results.keys()]\n",
    "    correlations = [result['correlation'] for result in results.values()]\n",
    "    p_values = [result['p_value'] for result in results.values()]\n",
    "    \n",
    "    # Create bar plot with thicker bars\n",
    "    bars = plt.bar(delays, correlations, \n",
    "                  width=200,\n",
    "                  alpha=1,\n",
    "                  edgecolor='black',\n",
    "                  linewidth=1.5)\n",
    "    \n",
    "    # Add correlation values slightly below the top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        y_pos = height + 0.02 if height >= 0 else height - 0.04\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, y_pos,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=11)\n",
    "    \n",
    "    # Add significance stars with more spacing\n",
    "    for i, (bar, p_val) in enumerate(zip(bars, p_values)):\n",
    "        height = bar.get_height()\n",
    "        stars = ''\n",
    "        if p_val < 0.001:\n",
    "            stars = '***'\n",
    "        elif p_val < 0.01:\n",
    "            stars = '**'\n",
    "        elif p_val < 0.05:\n",
    "            stars = '*'\n",
    "        \n",
    "        if stars:\n",
    "            y_pos = height + 0.06 if height >= 0 else height - 0.08\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, y_pos,\n",
    "                    stars,\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=12)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlabel('Delay (ms)', fontsize=12)\n",
    "    plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "    plt.title('Model-Monkey Behavior Correlation vs Delay', fontsize=14)\n",
    "    \n",
    "    # Set specific x-ticks\n",
    "    plt.xticks(delays, fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "    \n",
    "    # Add gridlines\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # Set y-axis limits to prevent text cutoff\n",
    "    ymin = min(correlations) - 0.2\n",
    "    ymax = max(correlations) + 0.15\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot with higher DPI for better quality\n",
    "    summary_plot_filename = os.path.join(results_dir, 'correlation_summary.png')\n",
    "    plt.savefig(summary_plot_filename, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved summary plot: {summary_plot_filename}\")\n",
    "\n",
    "def process_all_delays(delays, model_path, model_template, monkey_path, monkey_template):\n",
    "    \"\"\"\n",
    "    Process and save results for all specified delays.\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    results_dir = create_results_directory()\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each delay\n",
    "    for delay in delays:\n",
    "        print(f\"\\nProcessing delay: {delay}ms\")\n",
    "        \n",
    "        # Load and correlate data\n",
    "        model_data, monkey_data, r, p = load_and_correlate_behavior(\n",
    "            model_path,\n",
    "            model_template,\n",
    "            monkey_path,\n",
    "            monkey_template,\n",
    "            delay\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        all_results[str(delay)] = {\n",
    "            'correlation': float(r),\n",
    "            'p_value': float(p)\n",
    "        }\n",
    "        \n",
    "        # Create and save plot\n",
    "        fig = plot_correlation(model_data, monkey_data, delay, r, p)\n",
    "        plot_filename = os.path.join(results_dir, f'correlation_plot_{delay}ms.png')\n",
    "        fig.savefig(plot_filename)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved plot: {plot_filename}\")\n",
    "        \n",
    "        # Save raw data\n",
    "        data_filename = os.path.join(results_dir, f'correlation_data_{delay}ms.npz')\n",
    "        np.savez(data_filename, \n",
    "                 model_data=model_data, \n",
    "                 monkey_data=monkey_data)\n",
    "        print(f\"Saved data: {data_filename}\")\n",
    "    \n",
    "    # Create and save summary bar plot\n",
    "    plot_correlation_summary(all_results, results_dir)\n",
    "    \n",
    "    # Save summary results as JSON\n",
    "    results_filename = os.path.join(results_dir, 'correlation_results.json')\n",
    "    with open(results_filename, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    print(f\"\\nSaved summary results: {results_filename}\")\n",
    "    \n",
    "    return results_dir, all_results\n",
    "\n",
    "\n",
    "model_behavior_path = \"./\"\n",
    "model_behavior_template = \"B_I1_hvm200_{}ms.npy\"\n",
    "\n",
    "monkey_behavior_path = \"data/monkey_behavioral_data/\"\n",
    "monkey_behavior_template = \"b_i1_delay_{}.npy\"\n",
    "\n",
    "delays = [100, 400, 800, 1200]\n",
    "\n",
    "# Process all delays\n",
    "\n",
    "results_dir, results = process_all_delays(\n",
    "    delays,\n",
    "    model_behavior_path,\n",
    "    model_behavior_template,\n",
    "    monkey_behavior_path,\n",
    "    monkey_behavior_template\n",
    ")\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nSummary of correlations:\")\n",
    "print(\"----------------------\")\n",
    "for delay, result in results.items():\n",
    "    print(f\"Delay {delay}ms:\")\n",
    "    print(f\"  Correlation: {result['correlation']:.3f}\")\n",
    "    print(f\"  P-value: {result['p_value']:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376acf7-4f3e-455b-adf2-0ec359c236ce",
   "metadata": {},
   "source": [
    "# With noise-ceiling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55de8f49-cb23-4782-930b-575f5d9bf61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing delay: 100ms\n",
      "model_data.mean() = 0.6497701163731606, monkey_data.mean() = 0.918082398023673\n",
      "\n",
      "Processing delay: 400ms\n",
      "model_data.mean() = 0.6341095927948143, monkey_data.mean() = 0.922275953163999\n",
      "\n",
      "Processing delay: 800ms\n",
      "model_data.mean() = 0.5716948009513231, monkey_data.mean() = 0.8921462201243031\n",
      "\n",
      "Processing delay: 1200ms\n",
      "model_data.mean() = 0.5516149908845951, monkey_data.mean() = 0.8416626776251266\n",
      "Saved corrected correlation summary plot: correlation_monkey_and_model_noise_ceiling/correlation_summary_corrected.png\n",
      "\n",
      "Summary of correlations:\n",
      "----------------------\n",
      "Delay 100ms:\n",
      "  Raw correlation: 0.281\n",
      "  Corrected correlation: 0.298 ± 0.002\n",
      "  P-value: 5.540e-05\n",
      "Delay 400ms:\n",
      "  Raw correlation: 0.163\n",
      "  Corrected correlation: 0.190 ± 0.004\n",
      "  P-value: 2.071e-02\n",
      "Delay 800ms:\n",
      "  Raw correlation: -0.020\n",
      "  Corrected correlation: -0.025 ± 0.001\n",
      "  P-value: 7.758e-01\n",
      "Delay 1200ms:\n",
      "  Raw correlation: -0.158\n",
      "  Corrected correlation: -0.205 ± 0.008\n",
      "  P-value: 2.542e-02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def create_results_directory():\n",
    "    \"\"\"\n",
    "    Create a directory for storing correlation results.\n",
    "    Returns the path to the created directory.\n",
    "    \"\"\"\n",
    "    base_dir = \"correlation_monkey_and_model_noise_ceiling\"\n",
    "    # Add timestamp to avoid overwriting\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # results_dir = f\"{base_dir}_{timestamp}\"\n",
    "    results_dir = f\"{base_dir}\"\n",
    "    \n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"Created results directory: {results_dir}\")\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "def load_and_correlate_behavior(model_path, model_template, monkey_path, monkey_template, delay):\n",
    "    \"\"\"\n",
    "    Load and correlate model and monkey behavioral data for a specific delay.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_path : str\n",
    "        Path to model behavior data\n",
    "    model_template : str\n",
    "        Template string for model behavior filenames\n",
    "    monkey_path : str\n",
    "        Path to monkey behavior data\n",
    "    monkey_template : str\n",
    "        Template string for monkey behavior filenames\n",
    "    delay : int\n",
    "        Delay time in milliseconds\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (model_data, monkey_data, correlation_coefficient, p_value)\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    model_file = model_path + model_template.format(delay)\n",
    "    monkey_file = monkey_path + monkey_template.format(delay)\n",
    "    \n",
    "    model_data = np.load(model_file)\n",
    "    monkey_data = np.load(monkey_file)\n",
    "\n",
    "    print(f\"{model_data.mean() = }, {monkey_data.mean() = }\")\n",
    "    \n",
    "    # Flatten arrays if they're multidimensional\n",
    "    model_data = model_data.flatten()\n",
    "    monkey_data = monkey_data.flatten()\n",
    "    \n",
    "    # Calculate correlation\n",
    "    r, p = stats.pearsonr(model_data, monkey_data)\n",
    "    \n",
    "    return model_data, monkey_data, r, p\n",
    "\n",
    "def plot_correlation(model_data, monkey_data, delay, r, p):\n",
    "    \"\"\"\n",
    "    Create a scatter plot of model vs monkey behavioral data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_data : array-like\n",
    "        Model behavioral data\n",
    "    monkey_data : array-like\n",
    "        Monkey behavioral data\n",
    "    delay : int\n",
    "        Delay time in milliseconds\n",
    "    r : float\n",
    "        Correlation coefficient\n",
    "    p : float\n",
    "        P-value of correlation\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Create scatter plot\n",
    "    sns.scatterplot(x=monkey_data, y=model_data, alpha=0.5)\n",
    "    \n",
    "    # Add correlation line\n",
    "    z = np.polyfit(monkey_data, model_data, 1)\n",
    "    p_fit = np.poly1d(z)\n",
    "    plt.plot(monkey_data, p_fit(monkey_data), \"r--\", alpha=0.8, label='Correlation Line')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Monkey Behavior')\n",
    "    plt.ylabel('Model Behavior')\n",
    "    plt.title(f'Model vs Monkey Behavior Correlation\\nDelay: {delay}ms, r={r:.3f}, p={p:.3e}')\n",
    "    \n",
    "    # Add unity line\n",
    "    min_val = min(plt.xlim()[0], plt.ylim()[0])\n",
    "    max_val = max(plt.xlim()[1], plt.ylim()[1])\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.3, label='Unity Line')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "def load_reliability_data(delay: int, base_dir: str = \"behavioral_metrics_results\") -> np.ndarray:\n",
    "    \"\"\"Load reliability data for a specific delay\"\"\"\n",
    "    reliability_path = os.path.join(base_dir, f'delay_{delay}ms/bi1/reliabilities.npy')\n",
    "    return np.load(reliability_path)\n",
    "\n",
    "def calculate_corrected_correlation(\n",
    "    model_data: np.ndarray,\n",
    "    monkey_data: np.ndarray,\n",
    "    monkey_reliability: np.ndarray\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculate noise-ceiling corrected correlation and its standard deviation\n",
    "    \"\"\"\n",
    "    # Calculate raw correlation\n",
    "    raw_corr, p_val = stats.pearsonr(model_data, monkey_data)\n",
    "    \n",
    "    # Calculate corrected correlations for each reliability value\n",
    "    corrected_corrs = []\n",
    "    for rel in monkey_reliability:\n",
    "        # Correct correlation by dividing by sqrt(reliability)\n",
    "        corrected_corr = raw_corr / np.sqrt(rel)\n",
    "        # Ensure correlation doesn't exceed 1\n",
    "        corrected_corr = min(corrected_corr, 1.0)\n",
    "        corrected_corrs.append(corrected_corr)\n",
    "    \n",
    "    # Calculate mean and std of corrected correlations\n",
    "    mean_corrected = np.mean(corrected_corrs)\n",
    "    std_corrected = np.std(corrected_corrs)\n",
    "    \n",
    "    return mean_corrected, std_corrected, p_val\n",
    "\n",
    "def plot_correlation_summary_with_error(\n",
    "    results: Dict,\n",
    "    results_dir: str,\n",
    "    filename: str = 'correlation_summary_corrected.png'\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a bar plot comparing correlations across all delays with error bars\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Extract data\n",
    "    delays = [int(delay) for delay in results.keys()]\n",
    "    correlations = [result['corrected_correlation'] for result in results.values()]\n",
    "    errors = [result['correlation_std'] for result in results.values()]\n",
    "    p_values = [result['p_value'] for result in results.values()]\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = plt.bar(delays, correlations,\n",
    "                  width=200,\n",
    "                  alpha=1,\n",
    "                  edgecolor='black',\n",
    "                  linewidth=1.5)\n",
    "    \n",
    "    # Add error bars without caps\n",
    "    plt.errorbar(delays, correlations, yerr=errors,\n",
    "                fmt='none',  # No connecting line between points\n",
    "                capsize=0,   # No caps on error bars\n",
    "                color='black',\n",
    "                linewidth=1.5)\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i, (bar, corr, err) in enumerate(zip(bars, correlations, errors)):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height,\n",
    "                f'{corr:.3f}±{err:.3f}',\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Add significance stars\n",
    "    for i, (bar, p_val) in enumerate(zip(bars, p_values)):\n",
    "        height = bar.get_height()\n",
    "        stars = ''\n",
    "        if p_val < 0.001:\n",
    "            stars = '***'\n",
    "        elif p_val < 0.01:\n",
    "            stars = '**'\n",
    "        elif p_val < 0.05:\n",
    "            stars = '*'\n",
    "        \n",
    "        if stars:\n",
    "            y_pos = height + max(errors) + 0.05\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, y_pos,\n",
    "                    stars,\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=12)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlabel('Delay (ms)', fontsize=12)\n",
    "    plt.ylabel('Corrected Correlation Coefficient', fontsize=12)\n",
    "    plt.title('Model-Monkey Behavior Correlation vs Delay\\n(Reliability Corrected)', fontsize=14)\n",
    "    \n",
    "    plt.xticks(delays, fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Set y-axis limits to accommodate error bars and text\n",
    "    ymin = min(correlations) - max(errors) - 0.1\n",
    "    ymax = max(correlations) + max(errors) + 0.2\n",
    "    plt.ylim(ymin, ymax)\n",
    "    \n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(results_dir, filename)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved corrected correlation summary plot: {save_path}\")\n",
    "\n",
    "def process_all_delays_with_reliability(\n",
    "    delays: List[int],\n",
    "    model_path: str,\n",
    "    model_template: str,\n",
    "    monkey_path: str,\n",
    "    monkey_template: str,\n",
    "    reliability_base_dir: str = \"behavioral_metrics_results\"\n",
    ") -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    Process and save results for all delays with reliability correction\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    results_dir = create_results_directory()\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each delay\n",
    "    for delay in delays:\n",
    "        print(f\"\\nProcessing delay: {delay}ms\")\n",
    "        \n",
    "        # Load behavior data\n",
    "        model_data, monkey_data, raw_r, p = load_and_correlate_behavior(\n",
    "            model_path,\n",
    "            model_template,\n",
    "            monkey_path,\n",
    "            monkey_template,\n",
    "            delay\n",
    "        )\n",
    "        \n",
    "        # Load reliability data\n",
    "        reliability_data = load_reliability_data(delay, reliability_base_dir)\n",
    "        \n",
    "        # Calculate corrected correlation\n",
    "        corrected_r, r_std, p_value = calculate_corrected_correlation(\n",
    "            model_data, monkey_data, reliability_data\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        all_results[str(delay)] = {\n",
    "            'raw_correlation': float(raw_r),\n",
    "            'corrected_correlation': float(corrected_r),\n",
    "            'correlation_std': float(r_std),\n",
    "            'p_value': float(p_value)\n",
    "        }\n",
    "        \n",
    "        # Create and save individual correlation plots\n",
    "        fig = plot_correlation(model_data, monkey_data, delay, corrected_r, p_value)\n",
    "        plot_filename = os.path.join(results_dir, f'correlation_plot_{delay}ms.png')\n",
    "        fig.savefig(plot_filename)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Save raw data\n",
    "        data_filename = os.path.join(results_dir, f'correlation_data_{delay}ms.npz')\n",
    "        np.savez(data_filename,\n",
    "                 model_data=model_data,\n",
    "                 monkey_data=monkey_data,\n",
    "                 reliability_data=reliability_data)\n",
    "    \n",
    "    # Create and save summary plot with error bars\n",
    "    plot_correlation_summary_with_error(all_results, results_dir)\n",
    "    \n",
    "    # Save summary results\n",
    "    results_filename = os.path.join(results_dir, 'correlation_results.json')\n",
    "    with open(results_filename, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    \n",
    "    return results_dir, all_results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_behavior_path = \"./version_5_use_sth200_dataset/\"\n",
    "    model_behavior_template = \"B_I1_hvm200_{}ms.npy\"\n",
    "    \n",
    "    monkey_behavior_path = \"data/monkey_behavioral_data/\"\n",
    "    monkey_behavior_template = \"b_i1_delay_{}.npy\"\n",
    "    \n",
    "    delays = [100, 400, 800, 1200]\n",
    "    \n",
    "    # Process all delays with reliability correction\n",
    "    results_dir, results = process_all_delays_with_reliability(\n",
    "        delays,\n",
    "        model_behavior_path,\n",
    "        model_behavior_template,\n",
    "        monkey_behavior_path,\n",
    "        monkey_behavior_template,\n",
    "        reliability_base_dir=\"behavioral_metrics_results\"\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nSummary of correlations:\")\n",
    "    print(\"----------------------\")\n",
    "    for delay, result in results.items():\n",
    "        print(f\"Delay {delay}ms:\")\n",
    "        print(f\"  Raw correlation: {result['raw_correlation']:.3f}\")\n",
    "        print(f\"  Corrected correlation: {result['corrected_correlation']:.3f} ± {result['correlation_std']:.3f}\")\n",
    "        print(f\"  P-value: {result['p_value']:.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
